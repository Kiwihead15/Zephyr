{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiwihead15/Test-models/blob/main/question_answer_Zephyr_7B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kyxFE9_7OCJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chainlit as cl\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GXLI7XhDOyYQ"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"max_new_tokens\": 1024,\n",
        "    \"repetition_penalty\": 1.1,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.9,\n",
        "    \"stream\": True,\n",
        "    \"threads\": int(os.cpu_count() / 2)\n",
        "}\n",
        "\n",
        "local_llm = CTransformers(model='C:\\\\Users\\\\pbiosca\\\\AI\\\\Projects\\\\models\\\\zephyr-7b-beta.Q6_K.gguf', config=config)   # Path to the local gguf file\n",
        "#local_llm = CTransformers(model='TheBloke/zephyr-7B-beta-GGUF', model_file='zephyr-7b-beta.Q6_K.gguf', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m8oL05n2O4O2"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Please refer to factual information and don't make up fictional data/information.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=local_llm, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mQuestion: what is the capital city of Uruguay?\n",
            "\n",
            "Answer: Please refer to factual information and don't make up fictional data/information.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'what is the capital city of Uruguay?',\n",
              " 'text': '\\nThe correct answer is Montevideo, which is the largest city and capital of Uruguay, located in the southwestern region of the country. Other major cities in Uruguay include Salto, Paysandú, and Maldonado.'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain(\"what is the capital city of Uruguay?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhXG3A_XO8iX"
      },
      "outputs": [],
      "source": [
        "@cl.on_chat_start\n",
        "def main():\n",
        "    prompt = PromptTemplate(template=template, input_variables=['question'])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=local_llm, verbose=True)\n",
        "    cl.user_session.set(\"llm_chain\", llm_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFEkvUE8PDGu"
      },
      "outputs": [],
      "source": [
        "@cl.on_message\n",
        "async def main(message: str):\n",
        "    llm_chain = cl.user_session.get(\"llm_chain\")\n",
        "    res = await llm_chain.acall(message, callbacks=[cl.AsyncLangchainCallbackHandler()])\n",
        "    await cl.Message(content=res[\"text\"]).send()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyGJ1zI_PICR"
      },
      "outputs": [],
      "source": [
        "! chainlit run <name-oython-script>.py -w\n",
        "# The -w flag tells Chainlit to enable auto-reloading, so you don’t need to\n",
        "# restart the server every time you make changes to your application. \n",
        "# Your chatbot UI should now be accessible at http://localhost:8000."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOJROgk8L3J8jZT6ilItB2S",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
